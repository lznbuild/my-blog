
- blob.slice 分割file,SparkMD5 = name
- new FormData,  append(chunk)循环上传
- 后端创建文件流写入临时文件，定时任务清除
- 前端错误重传机制，保留成功上传的name
- 全部成功上传，调用merge接口，后端合并文件


二进制文件下载
```js
 // 创建对象 URL，生成下载链接
const downloadUrl = window.URL.createObjectURL(mergedBlob);

// 创建 <a> 元素并设置属性
const link = document.createElement('a');
link.href = downloadUrl;
link.setAttribute('download', 'file.txt');

// 模拟点击下载
link.click();

// 释放资源
window.URL.revokeObjectURL(downloadUrl);
```

```js
// 1. formData  后端通过multiparty包接收formdata，这个包不会做重复的检验,再把文件保留的路径给前端返回去做展示

// 2. 转换为base64
let fileRead = new FileReader()

fileRead.readAsDataURL(file)
fileRead.onload = (ev) => {
  result = ev.target.result // base64编码
}

发到后端 encodeURIComponent(result) 防止乱码
后端 decodeURIComponent(result) 解码


// 3.切片
SparkMD5，通过文件内容创建hash值，不会重复的存储相同的文件



fileRead.readAsArrayBuffer(file)
fileRead.onload = (ev) => {
  // 切换为buffer
  buffer = ev.target.result // base64编码

  // 切片

  // 每一个切片有自己的部分数据和自己的名字
  // hash-1
  // hash-2

  //SparkMD5生成hash
  spark = new SparkMD5.ArrayBuffer(),

  spark.append(buffer) // 生成hash
  hash = spark.end(); // 拿到这个hash
  suffix = /\.([0-9a-zA-Z])$/i.match(file.name)[1] // 后缀名

  let partList = []; // 所有切片
  partsize = file.size/100
  cur=0
  // 100个切片
  for(let i = 0; i <100;i++){
    let item ={
      chunk: file.slice(cur,partsize+cur)
      filename: `${hash}_${i}.${suffix}`
    }
    cur+=partsize
    partlist.push(item)
  }

  // 发请求
  partlist.foreach(item => {
    let formdata = new FormData()
    formdata.append('chunk',item.chunk);
    formdata.append('filename',item.filename);
    // 发送请求，可串行（好控制），可并行，成功上传后partlist.splice() 删除掉对应切片，后端通过hash建文件夹，存放所有切片
  })
  // 全部上传后发送另一个请求，表示上传完毕，hash当参数，后端merge所有切片 ，如果中途有失败的包，此接口返回失败的code,重新传,传过的切片再次上传很快

  // 点击暂停，不再发送请求 axios.abort()中断请求

}
```
